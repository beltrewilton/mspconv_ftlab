{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32157181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set current working directory to parent folder\n",
    "os.chdir(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81eb82",
   "metadata": {},
   "source": [
    "## Diarization (No se necesita, ya esta etiquetado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83e91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7b91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_ACCESS_TOKEN = json.load(open('config.json'))['HUGGINGFACE_ACCESS_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8323acd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emanu\\Anaconda3\\envs\\SER\\lib\\site-packages\\pyannote\\audio\\core\\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "C:\\Users\\emanu\\Anaconda3\\envs\\SER\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\emanu\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch_audiomentations\\utils\\io.py:27: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "torchvision is not available - cannot save figures\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.91M/5.91M [00:01<00:00, 5.16MB/s]\n",
      "config.yaml: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 399/399 [00:00<00:00, 57.6kB/s]\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26.6M/26.6M [00:00<00:00, 61.2MB/s]\n",
      "config.yaml: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:00<00:00, 31.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token= HUGGINGFACE_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a3cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the pipeline on an audio file\n",
    "diarization = pipeline(\"data/MSPCORPUS/Audio/MSP-Conversation_0002.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ca0741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"data/DIARIZATION/MSP-Conversation_0002.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c382d028",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.0s stop=3.6s speaker_SPEAKER_01\n",
      "start=3.9s stop=6.0s speaker_SPEAKER_01\n",
      "start=6.2s stop=7.5s speaker_SPEAKER_01\n",
      "start=7.8s stop=10.6s speaker_SPEAKER_01\n",
      "start=11.0s stop=14.0s speaker_SPEAKER_01\n",
      "start=14.4s stop=17.5s speaker_SPEAKER_01\n",
      "start=17.9s stop=22.0s speaker_SPEAKER_01\n",
      "start=22.2s stop=23.6s speaker_SPEAKER_01\n",
      "start=23.7s stop=25.7s speaker_SPEAKER_01\n",
      "start=26.0s stop=28.0s speaker_SPEAKER_01\n",
      "start=28.0s stop=30.1s speaker_SPEAKER_00\n",
      "start=30.4s stop=32.8s speaker_SPEAKER_00\n",
      "start=33.6s stop=40.4s speaker_SPEAKER_00\n",
      "start=41.0s stop=43.3s speaker_SPEAKER_00\n",
      "start=43.7s stop=46.0s speaker_SPEAKER_00\n",
      "start=46.3s stop=49.2s speaker_SPEAKER_00\n",
      "start=49.7s stop=55.1s speaker_SPEAKER_00\n",
      "start=55.4s stop=57.7s speaker_SPEAKER_00\n",
      "start=58.3s stop=59.7s speaker_SPEAKER_00\n",
      "start=60.2s stop=60.5s speaker_SPEAKER_01\n",
      "start=60.5s stop=61.0s speaker_SPEAKER_00\n",
      "start=61.0s stop=74.4s speaker_SPEAKER_01\n",
      "start=74.7s stop=82.2s speaker_SPEAKER_01\n",
      "start=82.6s stop=88.2s speaker_SPEAKER_01\n",
      "start=88.9s stop=96.5s speaker_SPEAKER_01\n",
      "start=90.8s stop=92.1s speaker_SPEAKER_00\n",
      "start=94.3s stop=94.7s speaker_SPEAKER_00\n",
      "start=95.4s stop=96.5s speaker_SPEAKER_00\n",
      "start=96.5s stop=96.6s speaker_SPEAKER_01\n",
      "start=96.6s stop=102.1s speaker_SPEAKER_00\n",
      "start=102.6s stop=106.5s speaker_SPEAKER_00\n",
      "start=106.9s stop=111.3s speaker_SPEAKER_00\n",
      "start=111.9s stop=114.5s speaker_SPEAKER_00\n",
      "start=115.0s stop=116.9s speaker_SPEAKER_00\n",
      "start=117.3s stop=119.9s speaker_SPEAKER_00\n",
      "start=120.4s stop=123.0s speaker_SPEAKER_00\n",
      "start=123.6s stop=126.4s speaker_SPEAKER_00\n",
      "start=127.1s stop=129.8s speaker_SPEAKER_00\n",
      "start=130.4s stop=132.5s speaker_SPEAKER_00\n",
      "start=132.9s stop=136.5s speaker_SPEAKER_00\n",
      "start=137.0s stop=139.5s speaker_SPEAKER_00\n",
      "start=139.9s stop=145.0s speaker_SPEAKER_00\n",
      "start=145.6s stop=147.9s speaker_SPEAKER_00\n",
      "start=148.4s stop=150.6s speaker_SPEAKER_00\n",
      "start=151.1s stop=155.3s speaker_SPEAKER_00\n",
      "start=155.8s stop=160.1s speaker_SPEAKER_00\n",
      "start=160.2s stop=165.4s speaker_SPEAKER_00\n",
      "start=165.8s stop=167.0s speaker_SPEAKER_00\n",
      "start=167.0s stop=167.7s speaker_SPEAKER_00\n",
      "start=168.1s stop=168.7s speaker_SPEAKER_00\n",
      "start=169.1s stop=172.9s speaker_SPEAKER_00\n",
      "start=173.5s stop=177.3s speaker_SPEAKER_00\n",
      "start=177.9s stop=181.0s speaker_SPEAKER_00\n",
      "start=181.6s stop=186.2s speaker_SPEAKER_00\n",
      "start=186.7s stop=192.0s speaker_SPEAKER_00\n",
      "start=192.4s stop=195.1s speaker_SPEAKER_00\n",
      "start=195.5s stop=198.8s speaker_SPEAKER_00\n",
      "start=199.4s stop=201.6s speaker_SPEAKER_00\n",
      "start=202.0s stop=204.0s speaker_SPEAKER_00\n",
      "start=204.6s stop=207.4s speaker_SPEAKER_00\n",
      "start=207.7s stop=211.8s speaker_SPEAKER_00\n",
      "start=212.1s stop=216.8s speaker_SPEAKER_00\n",
      "start=217.3s stop=220.4s speaker_SPEAKER_00\n",
      "start=220.6s stop=225.9s speaker_SPEAKER_01\n",
      "start=226.4s stop=228.8s speaker_SPEAKER_01\n",
      "start=229.0s stop=232.6s speaker_SPEAKER_01\n",
      "start=233.4s stop=236.4s speaker_SPEAKER_01\n",
      "start=236.9s stop=241.0s speaker_SPEAKER_01\n",
      "start=241.0s stop=241.2s speaker_SPEAKER_00\n",
      "start=241.4s stop=244.7s speaker_SPEAKER_00\n",
      "start=245.0s stop=249.2s speaker_SPEAKER_00\n",
      "start=249.7s stop=253.4s speaker_SPEAKER_00\n",
      "start=253.7s stop=256.1s speaker_SPEAKER_00\n",
      "start=256.5s stop=260.6s speaker_SPEAKER_00\n",
      "start=261.1s stop=264.9s speaker_SPEAKER_00\n",
      "start=265.4s stop=268.4s speaker_SPEAKER_00\n",
      "start=268.8s stop=273.7s speaker_SPEAKER_00\n",
      "start=274.4s stop=278.3s speaker_SPEAKER_00\n",
      "start=278.9s stop=281.3s speaker_SPEAKER_00\n",
      "start=281.5s stop=281.9s speaker_SPEAKER_01\n",
      "start=282.4s stop=282.4s speaker_SPEAKER_01\n",
      "start=282.4s stop=282.7s speaker_SPEAKER_00\n",
      "start=283.5s stop=283.5s speaker_SPEAKER_01\n",
      "start=283.5s stop=283.9s speaker_SPEAKER_00\n",
      "start=283.9s stop=288.3s speaker_SPEAKER_01\n",
      "start=288.8s stop=294.3s speaker_SPEAKER_01\n",
      "start=292.4s stop=292.5s speaker_SPEAKER_00\n",
      "start=294.8s stop=295.1s speaker_SPEAKER_01\n",
      "start=295.4s stop=302.2s speaker_SPEAKER_01\n",
      "start=302.5s stop=304.7s speaker_SPEAKER_01\n",
      "start=304.8s stop=306.6s speaker_SPEAKER_01\n",
      "start=306.8s stop=313.1s speaker_SPEAKER_01\n",
      "start=313.7s stop=318.4s speaker_SPEAKER_01\n",
      "start=319.1s stop=320.7s speaker_SPEAKER_01\n",
      "start=320.9s stop=321.4s speaker_SPEAKER_01\n",
      "start=322.3s stop=324.5s speaker_SPEAKER_01\n",
      "start=324.8s stop=329.6s speaker_SPEAKER_01\n",
      "start=329.9s stop=333.3s speaker_SPEAKER_01\n",
      "start=333.6s stop=334.1s speaker_SPEAKER_01\n",
      "start=335.0s stop=339.8s speaker_SPEAKER_01\n",
      "start=340.0s stop=349.9s speaker_SPEAKER_01\n",
      "start=350.1s stop=353.7s speaker_SPEAKER_01\n",
      "start=353.9s stop=366.2s speaker_SPEAKER_01\n",
      "start=366.7s stop=380.4s speaker_SPEAKER_01\n",
      "start=380.9s stop=383.8s speaker_SPEAKER_01\n",
      "start=383.9s stop=387.0s speaker_SPEAKER_01\n",
      "start=387.4s stop=388.1s speaker_SPEAKER_01\n",
      "start=388.6s stop=394.4s speaker_SPEAKER_01\n",
      "start=395.1s stop=397.4s speaker_SPEAKER_01\n",
      "start=397.9s stop=405.2s speaker_SPEAKER_01\n",
      "start=405.6s stop=409.1s speaker_SPEAKER_01\n",
      "start=409.7s stop=413.9s speaker_SPEAKER_01\n",
      "start=414.4s stop=416.6s speaker_SPEAKER_01\n",
      "start=416.9s stop=420.7s speaker_SPEAKER_01\n",
      "start=421.0s stop=424.6s speaker_SPEAKER_01\n",
      "start=424.9s stop=435.2s speaker_SPEAKER_01\n",
      "start=435.5s stop=436.6s speaker_SPEAKER_01\n",
      "start=437.0s stop=437.8s speaker_SPEAKER_01\n",
      "start=438.1s stop=441.4s speaker_SPEAKER_01\n",
      "start=441.5s stop=445.5s speaker_SPEAKER_01\n",
      "start=445.8s stop=448.7s speaker_SPEAKER_01\n",
      "start=448.9s stop=453.3s speaker_SPEAKER_01\n",
      "start=453.7s stop=456.3s speaker_SPEAKER_01\n",
      "start=456.7s stop=457.4s speaker_SPEAKER_01\n",
      "start=458.0s stop=459.7s speaker_SPEAKER_01\n",
      "start=459.9s stop=462.3s speaker_SPEAKER_01\n",
      "start=462.7s stop=462.9s speaker_SPEAKER_01\n",
      "start=463.6s stop=466.3s speaker_SPEAKER_01\n",
      "start=466.6s stop=471.9s speaker_SPEAKER_01\n",
      "start=472.7s stop=474.3s speaker_SPEAKER_01\n",
      "start=474.5s stop=476.4s speaker_SPEAKER_01\n",
      "start=476.5s stop=479.6s speaker_SPEAKER_01\n",
      "start=480.2s stop=482.3s speaker_SPEAKER_01\n",
      "start=482.5s stop=482.9s speaker_SPEAKER_01\n",
      "start=483.7s stop=487.4s speaker_SPEAKER_01\n",
      "start=487.6s stop=492.0s speaker_SPEAKER_01\n",
      "start=492.3s stop=493.4s speaker_SPEAKER_01\n",
      "start=493.9s stop=494.8s speaker_SPEAKER_01\n",
      "start=495.1s stop=507.7s speaker_SPEAKER_01\n",
      "start=507.7s stop=507.8s speaker_SPEAKER_00\n",
      "start=508.2s stop=515.0s speaker_SPEAKER_00\n",
      "start=515.6s stop=519.1s speaker_SPEAKER_00\n",
      "start=519.8s stop=525.9s speaker_SPEAKER_00\n",
      "start=526.4s stop=528.5s speaker_SPEAKER_00\n",
      "start=529.0s stop=531.6s speaker_SPEAKER_00\n",
      "start=532.2s stop=535.8s speaker_SPEAKER_00\n",
      "start=535.8s stop=538.3s speaker_SPEAKER_00\n",
      "start=538.6s stop=542.3s speaker_SPEAKER_00\n",
      "start=545.1s stop=551.1s speaker_SPEAKER_00\n",
      "start=550.8s stop=551.7s speaker_SPEAKER_01\n",
      "start=551.1s stop=552.4s speaker_SPEAKER_00\n",
      "start=552.4s stop=557.2s speaker_SPEAKER_01\n",
      "start=557.2s stop=559.1s speaker_SPEAKER_00\n",
      "start=559.6s stop=565.0s speaker_SPEAKER_00\n",
      "start=565.4s stop=568.0s speaker_SPEAKER_00\n",
      "start=567.5s stop=567.6s speaker_SPEAKER_01\n",
      "start=568.0s stop=572.5s speaker_SPEAKER_00\n",
      "start=572.9s stop=576.3s speaker_SPEAKER_00\n",
      "start=575.9s stop=579.5s speaker_SPEAKER_01\n",
      "start=579.9s stop=581.3s speaker_SPEAKER_01\n",
      "start=582.0s stop=582.8s speaker_SPEAKER_01\n",
      "start=583.0s stop=584.7s speaker_SPEAKER_01\n",
      "start=585.3s stop=586.1s speaker_SPEAKER_01\n",
      "start=587.1s stop=590.6s speaker_SPEAKER_01\n",
      "start=590.8s stop=594.8s speaker_SPEAKER_01\n",
      "start=593.1s stop=594.2s speaker_SPEAKER_00\n",
      "start=595.0s stop=599.6s speaker_SPEAKER_01\n",
      "start=600.0s stop=602.9s speaker_SPEAKER_01\n",
      "start=604.1s stop=605.5s speaker_SPEAKER_01\n",
      "start=605.7s stop=607.1s speaker_SPEAKER_01\n",
      "start=608.0s stop=609.5s speaker_SPEAKER_01\n",
      "start=610.1s stop=610.9s speaker_SPEAKER_01\n",
      "start=612.0s stop=612.7s speaker_SPEAKER_01\n",
      "start=612.9s stop=614.6s speaker_SPEAKER_01\n",
      "start=615.0s stop=621.2s speaker_SPEAKER_01\n",
      "start=621.6s stop=624.4s speaker_SPEAKER_01\n",
      "start=624.8s stop=631.6s speaker_SPEAKER_01\n",
      "start=628.5s stop=629.0s speaker_SPEAKER_00\n",
      "start=632.0s stop=638.4s speaker_SPEAKER_01\n",
      "start=632.0s stop=632.3s speaker_SPEAKER_00\n",
      "start=638.6s stop=639.9s speaker_SPEAKER_01\n",
      "start=640.4s stop=647.7s speaker_SPEAKER_01\n",
      "start=648.0s stop=648.4s speaker_SPEAKER_01\n",
      "start=648.6s stop=651.0s speaker_SPEAKER_01\n",
      "start=651.0s stop=651.2s speaker_SPEAKER_00\n",
      "start=651.2s stop=651.3s speaker_SPEAKER_01\n",
      "start=651.9s stop=657.2s speaker_SPEAKER_00\n",
      "start=657.4s stop=659.3s speaker_SPEAKER_00\n",
      "start=659.8s stop=661.4s speaker_SPEAKER_00\n",
      "start=660.9s stop=661.0s speaker_SPEAKER_01\n",
      "start=661.4s stop=665.9s speaker_SPEAKER_00\n",
      "start=666.4s stop=668.2s speaker_SPEAKER_00\n",
      "start=668.6s stop=670.9s speaker_SPEAKER_00\n",
      "start=671.8s stop=673.7s speaker_SPEAKER_01\n",
      "start=674.3s stop=675.9s speaker_SPEAKER_01\n",
      "start=676.4s stop=680.4s speaker_SPEAKER_01\n",
      "start=680.8s stop=681.5s speaker_SPEAKER_01\n",
      "start=681.7s stop=687.3s speaker_SPEAKER_01\n",
      "start=687.4s stop=695.2s speaker_SPEAKER_01\n",
      "start=695.7s stop=698.2s speaker_SPEAKER_01\n",
      "start=698.4s stop=704.3s speaker_SPEAKER_01\n",
      "start=704.4s stop=708.2s speaker_SPEAKER_01\n",
      "start=708.4s stop=712.0s speaker_SPEAKER_01\n",
      "start=709.6s stop=709.9s speaker_SPEAKER_00\n",
      "start=712.0s stop=720.2s speaker_SPEAKER_01\n",
      "start=712.3s stop=712.6s speaker_SPEAKER_00\n",
      "start=713.2s stop=713.4s speaker_SPEAKER_00\n",
      "start=720.5s stop=723.7s speaker_SPEAKER_01\n",
      "start=724.0s stop=726.0s speaker_SPEAKER_01\n",
      "start=726.2s stop=728.7s speaker_SPEAKER_01\n",
      "start=729.3s stop=730.5s speaker_SPEAKER_01\n",
      "start=730.9s stop=732.2s speaker_SPEAKER_01\n",
      "start=732.8s stop=736.3s speaker_SPEAKER_01\n",
      "start=736.5s stop=741.8s speaker_SPEAKER_01\n",
      "start=742.0s stop=742.7s speaker_SPEAKER_01\n",
      "start=742.9s stop=745.9s speaker_SPEAKER_01\n",
      "start=746.2s stop=753.9s speaker_SPEAKER_01\n",
      "start=754.3s stop=756.8s speaker_SPEAKER_01\n",
      "start=757.0s stop=760.4s speaker_SPEAKER_01\n",
      "start=760.6s stop=762.6s speaker_SPEAKER_01\n",
      "start=762.9s stop=763.5s speaker_SPEAKER_01\n",
      "start=763.8s stop=765.8s speaker_SPEAKER_01\n",
      "start=766.8s stop=770.6s speaker_SPEAKER_01\n",
      "start=770.7s stop=776.4s speaker_SPEAKER_01\n",
      "start=776.6s stop=781.0s speaker_SPEAKER_01\n",
      "start=781.4s stop=786.8s speaker_SPEAKER_01\n",
      "start=787.2s stop=791.7s speaker_SPEAKER_01\n",
      "start=792.1s stop=794.6s speaker_SPEAKER_01\n",
      "start=795.0s stop=798.3s speaker_SPEAKER_01\n",
      "start=798.7s stop=800.7s speaker_SPEAKER_01\n",
      "start=801.0s stop=801.0s speaker_SPEAKER_01\n",
      "start=801.0s stop=801.6s speaker_SPEAKER_00\n",
      "start=801.6s stop=801.7s speaker_SPEAKER_01\n",
      "start=801.7s stop=801.9s speaker_SPEAKER_00\n",
      "start=801.9s stop=802.0s speaker_SPEAKER_01\n",
      "start=802.0s stop=802.4s speaker_SPEAKER_00\n",
      "start=802.4s stop=802.4s speaker_SPEAKER_01\n",
      "start=802.4s stop=803.6s speaker_SPEAKER_00\n",
      "start=802.4s stop=802.5s speaker_SPEAKER_01\n",
      "start=804.0s stop=807.1s speaker_SPEAKER_00\n",
      "start=807.1s stop=807.1s speaker_SPEAKER_00\n",
      "start=807.3s stop=810.9s speaker_SPEAKER_00\n",
      "start=808.4s stop=808.9s speaker_SPEAKER_01\n",
      "start=809.4s stop=810.8s speaker_SPEAKER_01\n",
      "start=812.2s stop=820.4s speaker_SPEAKER_00\n",
      "start=820.7s stop=824.5s speaker_SPEAKER_00\n",
      "start=822.9s stop=824.0s speaker_SPEAKER_01\n",
      "start=824.7s stop=825.5s speaker_SPEAKER_00\n",
      "start=826.9s stop=843.2s speaker_SPEAKER_00\n",
      "start=843.6s stop=845.6s speaker_SPEAKER_00\n",
      "start=846.0s stop=849.6s speaker_SPEAKER_00\n",
      "start=850.0s stop=851.0s speaker_SPEAKER_00\n",
      "start=851.8s stop=855.8s speaker_SPEAKER_00\n",
      "start=856.4s stop=859.1s speaker_SPEAKER_00\n",
      "start=860.0s stop=861.1s speaker_SPEAKER_00\n",
      "start=861.6s stop=865.3s speaker_SPEAKER_00\n",
      "start=865.8s stop=869.8s speaker_SPEAKER_00\n",
      "start=870.3s stop=871.6s speaker_SPEAKER_00\n",
      "start=872.0s stop=875.5s speaker_SPEAKER_00\n",
      "start=876.1s stop=876.1s speaker_SPEAKER_01\n",
      "start=876.1s stop=876.9s speaker_SPEAKER_00\n",
      "start=876.9s stop=880.4s speaker_SPEAKER_01\n",
      "start=880.8s stop=883.8s speaker_SPEAKER_01\n",
      "start=884.1s stop=887.0s speaker_SPEAKER_01\n",
      "start=887.6s stop=893.5s speaker_SPEAKER_01\n",
      "start=894.2s stop=894.7s speaker_SPEAKER_01\n",
      "start=895.2s stop=901.6s speaker_SPEAKER_01\n",
      "start=901.8s stop=903.8s speaker_SPEAKER_01\n",
      "start=904.2s stop=907.1s speaker_SPEAKER_01\n",
      "start=907.3s stop=908.8s speaker_SPEAKER_01\n",
      "start=909.2s stop=914.1s speaker_SPEAKER_01\n",
      "start=915.2s stop=916.2s speaker_SPEAKER_01\n",
      "start=915.8s stop=916.0s speaker_SPEAKER_00\n",
      "start=916.3s stop=917.1s speaker_SPEAKER_01\n",
      "start=917.4s stop=920.2s speaker_SPEAKER_01\n",
      "start=920.5s stop=923.1s speaker_SPEAKER_01\n",
      "start=923.3s stop=926.6s speaker_SPEAKER_01\n",
      "start=927.0s stop=929.0s speaker_SPEAKER_01\n",
      "start=929.3s stop=930.7s speaker_SPEAKER_01\n",
      "start=930.9s stop=934.4s speaker_SPEAKER_01\n",
      "start=934.8s stop=942.8s speaker_SPEAKER_01\n",
      "start=943.0s stop=945.3s speaker_SPEAKER_01\n",
      "start=945.4s stop=948.8s speaker_SPEAKER_01\n",
      "start=948.9s stop=950.4s speaker_SPEAKER_01\n",
      "start=950.6s stop=954.0s speaker_SPEAKER_01\n",
      "start=954.4s stop=956.2s speaker_SPEAKER_01\n",
      "start=957.0s stop=959.6s speaker_SPEAKER_01\n",
      "start=959.8s stop=960.5s speaker_SPEAKER_01\n",
      "start=960.7s stop=961.8s speaker_SPEAKER_01\n",
      "start=962.1s stop=963.4s speaker_SPEAKER_01\n",
      "start=964.0s stop=967.2s speaker_SPEAKER_01\n",
      "start=967.4s stop=968.5s speaker_SPEAKER_01\n",
      "start=968.7s stop=971.0s speaker_SPEAKER_01\n",
      "start=971.3s stop=974.6s speaker_SPEAKER_01\n",
      "start=974.6s stop=974.6s speaker_SPEAKER_00\n",
      "start=974.6s stop=975.7s speaker_SPEAKER_01\n",
      "start=976.4s stop=976.7s speaker_SPEAKER_00\n",
      "start=976.9s stop=978.8s speaker_SPEAKER_00\n",
      "start=979.3s stop=982.1s speaker_SPEAKER_00\n",
      "start=982.5s stop=984.4s speaker_SPEAKER_00\n",
      "start=984.8s stop=986.1s speaker_SPEAKER_00\n",
      "start=986.6s stop=992.1s speaker_SPEAKER_00\n",
      "start=992.6s stop=995.4s speaker_SPEAKER_00\n",
      "start=996.0s stop=998.9s speaker_SPEAKER_00\n",
      "start=999.2s stop=1003.3s speaker_SPEAKER_00\n",
      "start=1004.0s stop=1005.9s speaker_SPEAKER_00\n",
      "start=1006.1s stop=1010.6s speaker_SPEAKER_00\n",
      "start=1011.1s stop=1013.1s speaker_SPEAKER_00\n",
      "start=1013.6s stop=1017.5s speaker_SPEAKER_00\n",
      "start=1018.0s stop=1020.2s speaker_SPEAKER_00\n",
      "start=1020.8s stop=1025.1s speaker_SPEAKER_00\n",
      "start=1025.4s stop=1027.9s speaker_SPEAKER_00\n",
      "start=1028.4s stop=1032.3s speaker_SPEAKER_00\n",
      "start=1032.9s stop=1033.8s speaker_SPEAKER_00\n",
      "start=1034.5s stop=1039.4s speaker_SPEAKER_00\n",
      "start=1039.8s stop=1041.8s speaker_SPEAKER_00\n",
      "start=1041.8s stop=1045.9s speaker_SPEAKER_00\n",
      "start=1045.5s stop=1046.4s speaker_SPEAKER_01\n",
      "start=1046.6s stop=1047.8s speaker_SPEAKER_01\n",
      "start=1048.1s stop=1055.1s speaker_SPEAKER_01\n",
      "start=1055.6s stop=1059.3s speaker_SPEAKER_01\n",
      "start=1059.7s stop=1064.4s speaker_SPEAKER_01\n",
      "start=1064.8s stop=1065.2s speaker_SPEAKER_01\n",
      "start=1065.5s stop=1070.9s speaker_SPEAKER_01\n",
      "start=1071.1s stop=1072.2s speaker_SPEAKER_01\n",
      "start=1072.5s stop=1074.0s speaker_SPEAKER_01\n",
      "start=1074.4s stop=1076.0s speaker_SPEAKER_01\n",
      "start=1076.6s stop=1077.9s speaker_SPEAKER_01\n",
      "start=1079.4s stop=1080.8s speaker_SPEAKER_01\n",
      "start=1081.0s stop=1082.1s speaker_SPEAKER_01\n",
      "start=1082.3s stop=1082.5s speaker_SPEAKER_00\n",
      "start=1082.8s stop=1083.5s speaker_SPEAKER_01\n",
      "start=1083.9s stop=1089.3s speaker_SPEAKER_01\n",
      "start=1089.8s stop=1091.0s speaker_SPEAKER_01\n",
      "start=1091.8s stop=1100.8s speaker_SPEAKER_01\n",
      "start=1101.2s stop=1101.7s speaker_SPEAKER_01\n",
      "start=1102.1s stop=1104.0s speaker_SPEAKER_01\n",
      "start=1104.0s stop=1104.4s speaker_SPEAKER_00\n",
      "start=1105.0s stop=1106.9s speaker_SPEAKER_00\n",
      "start=1107.5s stop=1111.0s speaker_SPEAKER_00\n",
      "start=1111.3s stop=1115.8s speaker_SPEAKER_00\n",
      "start=1116.3s stop=1118.6s speaker_SPEAKER_00\n",
      "start=1119.0s stop=1123.0s speaker_SPEAKER_00\n",
      "start=1123.6s stop=1125.1s speaker_SPEAKER_00\n",
      "start=1125.5s stop=1125.9s speaker_SPEAKER_00\n",
      "start=1126.0s stop=1127.4s speaker_SPEAKER_00\n",
      "start=1127.9s stop=1130.4s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e022276f",
   "metadata": {},
   "source": [
    "## Transcripción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b068795",
   "metadata": {},
   "source": [
    "### Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b503f",
   "metadata": {},
   "source": [
    "Transcripciones usando whisper para procesamiento del audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04515549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:04<00:00, 32.6MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51383ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = model.transcribe(\"data/MSPCORPUS/Audio/MSP-Conversation_0002.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9f7976",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's our honor to talk about important issues and why they're relevant to each of us. The foundation of our show, Heart of the Matter, focuses on three things. Important issues and why they should be on our radar today. Looking at things as right versus wrong, instead of right versus left. And sharing stories with real people's experiences so that we can brainstorm solutions to problems that we're facing today. We know we can do this together. Thanks for listening and joining the conversation. Kim, how does somebody connect with us today? Well, on Facebook, we are the Americhicks. Our email is Americhicks at Gmail. Our website is americhicks.com. And you can listen live there and call us at 303-477-5600. Molly, we have a really great show plan for you today. Race relations and affirmative action will have Droy Murdoch with us at the half hour. And we saw him at Leadership Program in the Rockies. And it was just a really interesting presentation. And then we will have states in other Laura Woods as well. So did you have a good week? I did have a good week. Thanks for asking. One thing that I realized though is that as gorgeous as my high heel boots are in the winter time with my winter outfits, they're not the smartest things to wear around Denver, Colorado in the winter time. When you get those days that go from snowy to then all the snow melts and it becomes ice, and then it snows over and then it becomes ice and back and forth and back and forth. Because I took a nice little digger the other day. I think I finally knocked some sense into myself. We'll see. A little keyster challenge here. Yeah, you let me know at the end of the show how I do. If I help to stimulate one mental ability or not, how about you? I had a great week. I actually did a road trip yesterday. I ran down to Kansas. My nephew's fiance, they had a bridal shower for her. And it was really, really just really a nice celebration. And then last night, the town that I'm from has a technical college. And they were, they have an annual dinner. And this was their 50th anniversary. And a girl, or I guess probably say woman, who I went to school with, is going to be the interim president there. But Molly, they have over these last 50 years given kids a great education. And they have, I think, 16 different programs and majors. And many of them are careers where you can be your own boss, such as cosmetology, welding, diesel technology. So there's been a lot of kids that have gone through those doors. And I think that it's really important as we look at what's happening to our young people. They need to be in a position where they can take care of themselves. The job market is really tough. And so getting a skill that you can make a living and take care of yourself is really important. And this little school in Northwest Kansas has been doing this for 50 years. So I'd like to give a shout out to them for work well done. Awesome. So with that, what's on my radar is local government, the more, as you know, I'm on city council of my little city. And we'll be coming up on my three-year anniversary. And now I finally know exactly where the water cooler is and the coffee machine. But I have really learned a lot over these last three years. And one of the things that I've realized is we need to make sure that we as citizens are involved in local government. So it could be local government zoning commissions, school boards. It is important for people to show up. It's important for people to have eyes on the process. Because when the citizen is engaged in watching, I think better decisions are made. So I would really like to encourage every one of you to at least choose one thing to become involved in and kind of keep eyes on the process. Let me ask you a question, Kim, because I've only gone to one city council meeting in my life. And I know that sounds terrible. But it just, you know, there's just so much going on that I haven't really thought about it. And I recently went to one. I get a question. Can you only go to your own city council or can you go to others? And if you go to others, can you speak up or can you only speak it your own? I mean, how does that work? Well, you should be able to go to any public meeting any place. So you're not precluded from that. And it kind of depends, I think, on the mayor what their protocol is. So some mayors will allow people, anybody that's there to speak and some won't. I personally think it's a great idea for people to have the opportunity to speak. Although, many times, I mean, if it could be a hot issue, for example, we just recently passed a construction defects ordinance. And there were a lot of people there. And I do think it's so important that everybody have an opportunity to speak. However, we did time that. I think we gave everybody two or three minutes just because otherwise we'd probably still be there. Yeah. Well, okay. I just, you know, I was watching the news, of course, and I saw that I think it was little 10. And their city just got rid of that whole red light thing, which I think is just awesome because I get those pictures in the mail of. Do you? I think that it should be important that if somebody's going to, if they're going to say that you ran a red light, there was a live human being there to say that you ran that red light and to come give you that ticket face to face. I'm over all these machines. And so let's go with that and get to the machines, shall we? Yeah. So here's my experience from this week. For the second time in the last three months, my personal credit card has been stolen. And I mean the numbers, right? So somehow somebody in a whole other state has created a credit card with my numbers on it that they're walking into a store and giving them this card. So I'm asking my credit card company, how in the world is that possible? Well, there are certain scanners that the grocery store and at the gas station and places like this, when you scan your card, that they can save and preserve your numbers on the card. And then they go create their own card. So I start figuring, okay, what am I going to do? There's got to be a way that I can protect myself because my card keeps getting stolen. And then somebody in North Carolina's buying food at the food market but I'm going to Macy's and they're denying me, telling me that no, I can't use my own card because it's been stolen. Okay, what do I do? So I start looking online and I'm like looking for other alternatives. And I see, okay, they've got this facial recognition software that some people are using, right? And fingerprints, fingerprints for security to get into different locations. They're using it on their dead bolts on their door at their houses. And I know they do it at the grocery stores too. Chicago specifically has several different stores, grocery stores and a few sunflower markets and places like that where they are allowing people to pay by their fingerprint. So okay, I think well then what happens now with the fingerprint, I've seen the old movies where they'd cut off somebody's finger in order to use their fingerprint to get into a place or what have you. And I'm not trying to be that scary but I'm thinking, my fingerprint is permanent information, it's permanent data, kind of like my social security number. Once it's comprised, it's gone forever. So what do you do about that? So do we want them to use our fingerprint or something else? What else can they use? So then I pull up this article and it is from NBC this year. And they are talking about the future of technology by the year 2017, we're all gonna have a chip in our skin that they're just gonna give you a little shot and it's like the size of a grain of rice and it goes into your skin and it's got your medical information. So okay, you know, you get in a car accident, you don't have any information on you, they know what you allergic to, things like that, right? Your history, your blood type, okay? I can see that. And but then they're saying it's also gonna be used for your money, like for your credit card transactions and things like that. So if somebody's walking past me and I've got this grain of rice chip in my hand and somebody goes past me, can't they do a scanner and just get that out from in my hand too? I mean, what is the answer for security and safety? And that's the big question, right? But then the other thing is, are they seriously gonna put chips in us where like every single person is gonna have a chip in their body and that's gonna be required? So they don't went further into my research and showed that the Affordable Care Act, the PPACA, actually allowed for that. Really? Yes. Do you say it's like on page 1500 or something? 1500 or something, it talks about the two different medical devices that they're authorizing them to use and part one of them is for them to allow these chips to go into our bodies for medical purposes. You know, Molly, on the one hand, you can make a case for that as you said, your credit card has been stolen and compromised. And so you could go down a natural progression to this chip. However, I think that even though something may seem like a possible good idea, we need to go back to the Fourth Amendment. This idea that people can be secure in their persons, their houses, their papers and effects under against unreasonable search. So when we come back, let's talk about that because something that may seem like a good idea is probably a very bad idea. Welcome back to Heart of the Matter. I'm Kim Munson here with my good friend Molly Voe. Did you choose that song? I sure did. I had a feeling. Well, you know, the singer actually just passed away and that was just such an awesome song and I thought we would say it in her honor. Well, very nice, very nice. Hey, when we went to break, we were talking about something that is of great concern and it's this chip thing that you said would be for identity. And you said that it was deeply embedded, no pun intended, into the Affordable Care Act. Did you find what page that was on? I did. So here it is. Page 1501 in the PPACA. And it talks about national device medical registry and it talks about class two is implantable. This is what they're gonna allow them to do. Is it there? It's an implantable radio frequency transponder system for patient information and identification. And this can hold medical, financial and criminal information. Does that say that? Yes. Yes. Oh my gosh. So that's scary. Yeah, that's scary. Because also, okay, so say this chip is in my body and it's got my medical and my financial information. Now we see people that are getting into the computer systems and hacking systems all the time. Right, right. So what if somebody goes in and hacks my medical information? Right, right. What if somebody goes in and hacks my financial information? So I don't have a bank account anymore, right? I don't have a credit card anymore. And I had, let's say, $1,000 in the account and I don't know, somebody thinks I did something bad and they want to go in and hack it. Now I've only got $2 in my account. I just, it's scary to me to think about this. You know, it sounds like it could be like a born identity thing, though. Right. So like in the espionage or whatever, they could implant somebody else's chip in you. Yeah. But Molly, I mean, this is really of great concern. What do you think the solution is? I think we as citizens say, no, to that, right? I think we absolutely say no to that. Yeah. But how do we do it? Well, I mean, one thing is I know that people are talking about getting rid of the Affordable Care Act, you know, scrapping it and starting over, which I think makes sense because we know it was passed illegally, right? The way it was passed was illegal. And now that you see that all these things inside this bill have nothing to do with actually helping health care, which it was supposedly created to do. The Affordable Care Act was supposed to solve a problem and make it more affordable and more accessible for all of us to get access to health care. What we've seen is that the opposite of has happened. You yourself got the doctor from your doctor that he's leaving. And so you are now changing his practice. You're changing practice, right? So so many people are getting these letters. The doctors are leaving. Now they've got to get on a waiting list to get in to see somebody new, get in the back of the line. Right, I'm sure they're going to keep the people that they had with them for years and years first. So now everybody's going to be waiting to get in line. Prices have gone up rather than down. Right. And with less doctors and more people looking for services, we've got a shortage of health care. So not only is it not done when it said it was going to do it's hurt people more than it's helped, but then you start looking into the details in the Affordable Care Act and you see, wow, they're saying that they can implant something in my body if they want to that has my medical and financial information on it. That doesn't seem good. And I don't know where it is in the in the writing, but I remember one time our friend Dr. Jovechio talking about something else that was in that Affordable Care Act saying that if you had a young child in your home that they could come to your house at any time, the government could come to your house at any time under the guise of checking to see if you have a weapon in your home and if it's put away safely or not, just because you have a child. And this isn't because they know you have a gun. This is just anybody. So it kind of opens up all these other control issues. Control issues and big government and big brother and it takes away our personal rights. I mean, if you want to take away our personal rights and I think you should do it the legal way going through the constitution and if you want to get rid of the Fourth Amendment, you want to get rid of the First Amendment, you want to get rid of the Bill of Rights, then you know what, do it the legal way. But when you do the amendment process, right? Through the amendment process. Which I don't think that that would really fly. So your point is this is. Thanks for telling me my point. I know that I've gone hit my head. But it's really important that people think about this that instead of letting bureaucrats and politicians chip away at these rights that were given to us in the constitution with the chip, can we? But a boom. We as citizens need to say, hold on, wait a minute. And what happens is all these things are always brought up to us as helping people, helping the children, helping, helping, helping. But when you look at the net effect, what happens is it really hurts people. I was talking to some women recently, a good friend of mine is just going on Medicare and she's diabetic. And she is absolutely terrified because she said that her medication is gonna be $4,000 a month. And she's not, I mean, she's looking at all different kinds of options regarding this medication, but it's not working out so well for her, Molly. And she is really terrified. She's single and $4,000 a month for medication is pretty significant. Right, right. Well, I think I told you, I met a woman on the airplane about a month ago and told her what we did. And she's like, wow, she's like, you know, with that new healthcare thing, she's like, it's really hurting me. She said, I was on my husband, or we were talking really kind of, you know, Medicare and the history of Medicare. And that's actually why our medical expenses were so high to begin with. And so then the government came up with the solution to the problem that they solved in the first place. And now it's, you know, just getting bigger and bigger. But she said because of Medicare, Medicare is hurt her because she was on her husband's plan and with his employer plan, and she should have been allowed to stay on that forever as beneficiary. But then in, he passed and she was on it as a beneficiary for life. But of course, as soon as she turned 65, she was required to get off of that insurance where she only had to pay like $100 a month for this awesome, fully covered insurance. Now she has to go into Medicare where she's having to spend $200 a month or $280 a month and so many things aren't covered. So now there's more money coming out of her pocket. She's got the deductibles, she's got the out of pockets that she has to hit every year. So now because she's 65, she's being forced off this nice, generous, private employer plan and forced onto the government plan, which is giving her less services for more money. And it's just a pain. If the government comes up with solutions to the problems they solved in the first place, that's the point. That's the point. People should look and say, should the government be the solution to this problem or not? We'll figure out where did it start? Because a lot of times, they're creating solutions to their own problems which are making them bigger, more expensive and more painful for the people, they say they're trying to help. Well, and that is what is of great concern is under this guise of helping people, people are really being hurt. And then there's the force and there's the penalties I was talking to a young girl. Just recently she got out of college. Last year she paid the penalty because she did not have insurance. This year she thinks that she's gonna get insurance. However, I don't think that people realize it can be up to 2% of your income. And what's with that, Molly? Somebody can't have the choice on whether or not they want to get healthcare or not. And then the option of getting like a policy just a catastrophic policy has been taken away. And that's not what government is supposed to be doing. I think the real in game is not helping people. It's trying to control people, which I guess circles back to this concern that you have with this chip that you said you also saw in NBC News that ultimately this will be, something that could be used to control people instead of helping people. So I guess going back to Ronald Reagan, some of the most terrifying words you can ever hear is I'm from the government and I'm here to help you. Exactly, Ron, when you hear that. And this article is it, take a look at it. I had all posted up. I actually posted it on my personal Facebook but I'll post it on the America's too. Because I want people to know, I mean, I didn't get this off some crazy site, right? This is NBC News. Tell me if anyone knows this is wrong, that's fine, call and tell me I want to know. Because it's scary, it's scaring me. It says that October 9th of last year, the FDA approved the use of a tiny computer chip called the Vera chip for implementation and people and it will hold the medical history for doctors and hospitals. I just don't like it. I'm just worried about it. Because I've heard that people now, when they go in to see their doctor, their doctors are starting to ask them, do they have a gun in the house? And more and more, they're asking them, are you sad or you nervous if you ever been depressed? Well, who hasn't had a moment of sadness? Who hasn't lost a parent or something like that? It's just, these questions are getting concerning to me. Well, they really are. And, you know, we continue to move towards this idea, Martin Luther King Jr. said, that we want to get to a point where we are judged on the content of our character versus the color of our skin. We're seeing all of this divisiveness, all this identity politics in America right now. So I went in for a checkup. I think I might have even said this a few months ago. And so the first thing they asked me was, my race.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4d13",
   "metadata": {},
   "source": [
    "### Stable whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3be3c",
   "metadata": {},
   "source": [
    "La gran diferencia que tiene con whisper es que da escalas de tiempo mas exactas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff7e1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stable_whisper\n",
    "model = stable_whisper.load_model('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e70b0891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emanu\\Anaconda3\\envs\\SER\\lib\\site-packages\\stable_whisper\\whisper_word_level.py:224: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribe:   0%|                                                                                                                                                                  | 0/1130.48 [00:01<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1130.48/1130.48 [07:33<00:00,  2.49sec/s]\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"data/MSPCORPUS/Audio/MSP-Conversation_0002.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de como guardar un json con la transcripcion\n",
    "result.save_as_json('data/TRANSCRIPCIONES/MSP-Conversation_0002.wav.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "723dcc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\emanu\\Documents\\GitHub\\mspconv_ftlab\\audio.srt\n",
      "Saved: C:\\Users\\emanu\\Documents\\GitHub\\mspconv_ftlab\\audio.vtt\n",
      "Saved: C:\\Users\\emanu\\Documents\\GitHub\\mspconv_ftlab\\audio.ass\n",
      "Saved: C:\\Users\\emanu\\Documents\\GitHub\\mspconv_ftlab\\audio.tsv\n"
     ]
    }
   ],
   "source": [
    "# Guardar el audio en distintos formatos\n",
    "result.to_srt_vtt('audio.srt') #SRT\n",
    "result.to_srt_vtt('audio.vtt') #VTT\n",
    "result.to_ass('audio.ass') #ASS\n",
    "result.to_tsv('audio.tsv') #TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3e21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de como leer un json con la transcripción\n",
    "result2 = stable_whisper.WhisperResult('audio.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5677c5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordTiming(word=\" It's\", start=0.0, end=0.16, probability=0.7852025926113129, tokens=[467, 311], left_locked=False, right_locked=False, segment_id=0, id=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72dd1f2",
   "metadata": {},
   "source": [
    "#### PELIGRO, NO CORRER, LOOP QUE GENERA LOS JSON DE TODAS LAS TRANSCRIPCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09fc622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/MSPCORPUS/Audio\\MSP-Conversation_0002.wav MSP-Conversation_0002.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0021.wav MSP-Conversation_0021.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0023.wav MSP-Conversation_0023.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0035.wav MSP-Conversation_0035.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0043.wav MSP-Conversation_0043.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0046.wav MSP-Conversation_0046.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0047.wav MSP-Conversation_0047.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0053.wav MSP-Conversation_0053.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0054.wav MSP-Conversation_0054.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0055.wav MSP-Conversation_0055.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0061.wav MSP-Conversation_0061.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0067.wav MSP-Conversation_0067.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0079.wav MSP-Conversation_0079.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0081.wav MSP-Conversation_0081.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0083.wav MSP-Conversation_0083.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0087.wav MSP-Conversation_0087.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0088.wav MSP-Conversation_0088.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0094.wav MSP-Conversation_0094.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0101.wav MSP-Conversation_0101.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0103.wav MSP-Conversation_0103.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0110.wav MSP-Conversation_0110.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0114.wav MSP-Conversation_0114.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0125.wav MSP-Conversation_0125.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0130.wav MSP-Conversation_0130.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0135.wav MSP-Conversation_0135.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0140.wav MSP-Conversation_0140.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0147.wav MSP-Conversation_0147.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0153.wav MSP-Conversation_0153.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0156.wav MSP-Conversation_0156.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0157.wav MSP-Conversation_0157.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0160.wav MSP-Conversation_0160.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0166.wav MSP-Conversation_0166.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0167.wav MSP-Conversation_0167.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0172.wav MSP-Conversation_0172.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0180.wav MSP-Conversation_0180.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0183.wav MSP-Conversation_0183.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0184.wav MSP-Conversation_0184.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0190.wav MSP-Conversation_0190.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0197.wav MSP-Conversation_0197.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0201.wav MSP-Conversation_0201.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0202.wav MSP-Conversation_0202.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0207.wav MSP-Conversation_0207.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0218.wav MSP-Conversation_0218.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0227.wav MSP-Conversation_0227.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0228.wav MSP-Conversation_0228.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0231.wav MSP-Conversation_0231.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0235.wav MSP-Conversation_0235.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0251.wav MSP-Conversation_0251.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0257.wav MSP-Conversation_0257.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0260.wav MSP-Conversation_0260.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0261.wav MSP-Conversation_0261.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0269.wav MSP-Conversation_0269.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0278.wav MSP-Conversation_0278.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0281.wav MSP-Conversation_0281.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0289.wav MSP-Conversation_0289.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0295.wav MSP-Conversation_0295.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0297.wav MSP-Conversation_0297.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0300.wav MSP-Conversation_0300.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0319.wav MSP-Conversation_0319.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0325.wav MSP-Conversation_0325.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0338.wav MSP-Conversation_0338.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0340.wav MSP-Conversation_0340.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0344.wav MSP-Conversation_0344.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0361.wav MSP-Conversation_0361.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0372.wav MSP-Conversation_0372.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0380.wav MSP-Conversation_0380.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0381.wav MSP-Conversation_0381.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0396.wav MSP-Conversation_0396.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0397.wav MSP-Conversation_0397.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0401.wav MSP-Conversation_0401.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0417.wav MSP-Conversation_0417.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0418.wav MSP-Conversation_0418.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0420.wav MSP-Conversation_0420.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0422.wav MSP-Conversation_0422.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0436.wav MSP-Conversation_0436.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0437.wav MSP-Conversation_0437.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0456.wav MSP-Conversation_0456.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0475.wav MSP-Conversation_0475.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0489.wav MSP-Conversation_0489.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0498.wav MSP-Conversation_0498.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0504.wav MSP-Conversation_0504.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0522.wav MSP-Conversation_0522.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0538.wav MSP-Conversation_0538.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0541.wav MSP-Conversation_0541.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0544.wav MSP-Conversation_0544.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0552.wav MSP-Conversation_0552.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0563.wav MSP-Conversation_0563.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0566.wav MSP-Conversation_0566.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0569.wav MSP-Conversation_0569.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0575.wav MSP-Conversation_0575.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0584.wav MSP-Conversation_0584.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0590.wav MSP-Conversation_0590.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0593.wav MSP-Conversation_0593.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0597.wav MSP-Conversation_0597.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0600.wav MSP-Conversation_0600.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0611.wav MSP-Conversation_0611.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0627.wav MSP-Conversation_0627.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0637.wav MSP-Conversation_0637.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0642.wav MSP-Conversation_0642.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0646.wav MSP-Conversation_0646.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0653.wav MSP-Conversation_0653.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0654.wav MSP-Conversation_0654.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0657.wav MSP-Conversation_0657.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0672.wav MSP-Conversation_0672.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0675.wav MSP-Conversation_0675.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0678.wav MSP-Conversation_0678.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0681.wav MSP-Conversation_0681.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0683.wav MSP-Conversation_0683.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0686.wav MSP-Conversation_0686.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0690.wav MSP-Conversation_0690.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0692.wav MSP-Conversation_0692.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0700.wav MSP-Conversation_0700.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0706.wav MSP-Conversation_0706.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0709.wav MSP-Conversation_0709.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0714.wav MSP-Conversation_0714.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0715.wav MSP-Conversation_0715.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0722.wav MSP-Conversation_0722.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0726.wav MSP-Conversation_0726.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0727.wav MSP-Conversation_0727.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0735.wav MSP-Conversation_0735.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0744.wav MSP-Conversation_0744.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0746.wav MSP-Conversation_0746.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0748.wav MSP-Conversation_0748.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0760.wav MSP-Conversation_0760.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0765.wav MSP-Conversation_0765.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0770.wav MSP-Conversation_0770.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0772.wav MSP-Conversation_0772.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0782.wav MSP-Conversation_0782.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0791.wav MSP-Conversation_0791.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0792.wav MSP-Conversation_0792.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0796.wav MSP-Conversation_0796.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0802.wav MSP-Conversation_0802.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0821.wav MSP-Conversation_0821.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0823.wav MSP-Conversation_0823.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0830.wav MSP-Conversation_0830.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0835.wav MSP-Conversation_0835.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0841.wav MSP-Conversation_0841.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0858.wav MSP-Conversation_0858.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0869.wav MSP-Conversation_0869.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0878.wav MSP-Conversation_0878.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0883.wav MSP-Conversation_0883.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0893.wav MSP-Conversation_0893.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0900.wav MSP-Conversation_0900.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0905.wav MSP-Conversation_0905.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0912.wav MSP-Conversation_0912.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0942.wav MSP-Conversation_0942.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0943.wav MSP-Conversation_0943.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0952.wav MSP-Conversation_0952.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0962.wav MSP-Conversation_0962.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0993.wav MSP-Conversation_0993.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_0996.wav MSP-Conversation_0996.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1009.wav MSP-Conversation_1009.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1021.wav MSP-Conversation_1021.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1040.wav MSP-Conversation_1040.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1116.wav MSP-Conversation_1116.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1124.wav MSP-Conversation_1124.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1130.wav MSP-Conversation_1130.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1140.wav MSP-Conversation_1140.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1151.wav MSP-Conversation_1151.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1154.wav MSP-Conversation_1154.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1159.wav MSP-Conversation_1159.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1167.wav MSP-Conversation_1167.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1170.wav MSP-Conversation_1170.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1173.wav MSP-Conversation_1173.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1180.wav MSP-Conversation_1180.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1183.wav MSP-Conversation_1183.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1184.wav MSP-Conversation_1184.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1185.wav MSP-Conversation_1185.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1186.wav MSP-Conversation_1186.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1187.wav MSP-Conversation_1187.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1188.wav MSP-Conversation_1188.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1189.wav MSP-Conversation_1189.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1190.wav MSP-Conversation_1190.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1191.wav MSP-Conversation_1191.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1198.wav MSP-Conversation_1198.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1200.wav MSP-Conversation_1200.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1219.wav MSP-Conversation_1219.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1258.wav MSP-Conversation_1258.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1277.wav MSP-Conversation_1277.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1339.wav MSP-Conversation_1339.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1353.wav MSP-Conversation_1353.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1356.wav MSP-Conversation_1356.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1358.wav MSP-Conversation_1358.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1369.wav MSP-Conversation_1369.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1406.wav MSP-Conversation_1406.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1413.wav MSP-Conversation_1413.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1421.wav MSP-Conversation_1421.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1424.wav MSP-Conversation_1424.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1452.wav MSP-Conversation_1452.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1464.wav MSP-Conversation_1464.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1486.wav MSP-Conversation_1486.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1512.wav MSP-Conversation_1512.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1523.wav MSP-Conversation_1523.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1536.wav MSP-Conversation_1536.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1540.wav MSP-Conversation_1540.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1545.wav MSP-Conversation_1545.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1560.wav MSP-Conversation_1560.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1568.wav MSP-Conversation_1568.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1599.wav MSP-Conversation_1599.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1609.wav MSP-Conversation_1609.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1621.wav MSP-Conversation_1621.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1630.wav MSP-Conversation_1630.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1637.wav MSP-Conversation_1637.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1642.wav MSP-Conversation_1642.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1657.wav MSP-Conversation_1657.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1669.wav MSP-Conversation_1669.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1684.wav MSP-Conversation_1684.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1701.wav MSP-Conversation_1701.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1710.wav MSP-Conversation_1710.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1752.wav MSP-Conversation_1752.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1870.wav MSP-Conversation_1870.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1884.wav MSP-Conversation_1884.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1890.wav MSP-Conversation_1890.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1892.wav MSP-Conversation_1892.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1896.wav MSP-Conversation_1896.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1917.wav MSP-Conversation_1917.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1922.wav MSP-Conversation_1922.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1925.wav MSP-Conversation_1925.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1926.wav MSP-Conversation_1926.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1931.wav MSP-Conversation_1931.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1940.wav MSP-Conversation_1940.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1960.wav MSP-Conversation_1960.wav\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1968.wav MSP-Conversation_1968.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emanu\\Anaconda3\\envs\\SER\\lib\\site-packages\\stable_whisper\\whisper_word_level.py:224: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribe:   0%|                                                                                                                                                                   | 0/914.83 [00:01<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 914.83/914.83 [05:10<00:00,  2.94sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\emanu\\Documents\\GitHub\\mspconv_ftlab\\data\\TRANSCRIPCIONES\\MSP-Conversation_1968.wav.json\n",
      "data/MSPCORPUS/Audio\\MSP-Conversation_1992.wav MSP-Conversation_1992.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|                                                                                                                                                                   | 0/676.55 [00:01<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   4%|██████▌                                                                                                                                                | 29.32/676.55 [00:19<07:06,  1.52sec/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(f,filename)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(filename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1968\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     result\u001b[38;5;241m.\u001b[39msave_as_json(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/TRANSCRIPCIONES/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\stable_whisper\\whisper_word_level.py:471\u001b[0m, in \u001b[0;36mtranscribe_stable\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, regroup, ts_num, ts_noise, suppress_silence, suppress_word_ts, q_levels, k_size, time_scale, demucs, demucs_output, demucs_options, vad, vad_threshold, vad_onnx, min_word_dur, only_voice_freq, prepend_punctuations, append_punctuations, mel_first, split_callback, suppress_ts_tokens, gap_padding, only_ffmpeg, max_instant_words, avg_prob_threshold, progress_callback, ignore_compatibility, **decode_options)\u001b[0m\n\u001b[0;32m    469\u001b[0m detect_language()\n\u001b[0;32m    470\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 471\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mts_token_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_token_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    472\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\stable_whisper\\whisper_word_level.py:344\u001b[0m, in \u001b[0;36mtranscribe_stable.<locals>.decode_with_fallback\u001b[1;34m(seg, ts_token_mask)\u001b[0m\n\u001b[0;32m    341\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    343\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m--> 344\u001b[0m decode_result, audio_features \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_stable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mseg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mts_token_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_token_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msuppress_ts_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    352\u001b[0m         compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    354\u001b[0m ):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\stable_whisper\\decode.py:107\u001b[0m, in \u001b[0;36mdecode_stable\u001b[1;34m(model, mel, options, ts_token_mask, audio_features, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m task \u001b[38;5;241m=\u001b[39m DecodingTaskStable(model, options, ts_token_mask\u001b[38;5;241m=\u001b[39mts_token_mask, audio_features\u001b[38;5;241m=\u001b[39maudio_features)\n\u001b[1;32m--> 107\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result, task\u001b[38;5;241m.\u001b[39maudio_features\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\whisper\\decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[1;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[0;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\stable_whisper\\decode.py:42\u001b[0m, in \u001b[0;36mDecodingTaskStable._main_loop\u001b[1;34m(self, audio_features, tokens)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[1;32m---> 42\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[0;32m     45\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\whisper\\decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[1;34m(self, tokens, audio_features)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\whisper\\model.py:211\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[1;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[0;32m    208\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 211\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[0;32m    214\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    215\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\whisper\\model.py:136\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    131\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     kv_cache: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    135\u001b[0m ):\n\u001b[1;32m--> 136\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m    138\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\whisper\\model.py:84\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kv_cache:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# otherwise, perform key/value projections for self- or cross-attention as usual.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(x \u001b[38;5;28;01mif\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xa)\n\u001b[1;32m---> 84\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# for cross-attention, calculate keys and values once and reuse in subsequent calls.\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     k \u001b[38;5;241m=\u001b[39m kv_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\torch\\nn\\modules\\module.py:1581\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1581\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1584\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\SER\\lib\\site-packages\\whisper\\model.py:301\u001b[0m, in \u001b[0;36mWhisper.install_kv_cache_hooks.<locals>.save_to_cache\u001b[1;34m(module, _, output)\u001b[0m\n\u001b[0;32m    299\u001b[0m     cache[module] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m     cache[module] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[module]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "directory = 'data/MSPCORPUS/Audio'\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        print(f,filename)\n",
    "        if int(filename.split('_')[1].split('.')[0]) >= 1968:\n",
    "            result = model.transcribe(f)\n",
    "            result.save_as_json(f'data/TRANSCRIPCIONES/{filename}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878665b6",
   "metadata": {},
   "source": [
    "## Cargando transcripciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fe3016",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import stable_whisper\n",
    "model = stable_whisper.load_model('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308355cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = stable_whisper.WhisperResult('./data/TRANSCRIPCIONES/MSP-Conversation_0002.wav.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a7f4301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for result in results:\n",
    "    X.append(result.end - result.start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0219447f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.080237580993522"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "SER",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
